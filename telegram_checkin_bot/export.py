import os
import re
import pandas as pd
import pytz
import shutil
import zipfile
import requests
import logging
from datetime import datetime, time
from sqlalchemy import create_engine
from concurrent.futures import ThreadPoolExecutor
from config import DATA_DIR, DATABASE_URL
import cloudinary
import cloudinary.uploader
from openpyxl import load_workbook
from openpyxl.styles import PatternFill


# æ—¥å¿—é…ç½®
logging.basicConfig(level=logging.INFO, format="[%(asctime)s] %(levelname)s: %(message)s")

MAX_TELEGRAM_FILE_MB = 50
BEIJING_TZ = pytz.timezone("Asia/Shanghai")

# ç­æ¬¡æ—¶é—´å®šä¹‰
SHIFT_TIMES = {
    "Fç­": (time(12, 0), time(21, 0)),
    "Gç­": (time(13, 0), time(22, 0)),
    "Hç­": (time(14, 0), time(23, 0)),
    "Iç­": (time(15, 0), time(0, 0)),  # è·¨å¤©å¤„ç†
}

def safe_filename(name: str) -> str:
    return re.sub(r'[\\/*?:"<>|]', "_", str(name))

def upload_to_cloudinary(file_path: str) -> str | None:
    try:
        result = cloudinary.uploader.upload(
            file_path,
            resource_type="raw",
            folder="telegram_exports",
            public_id=os.path.splitext(os.path.basename(file_path))[0]
        )
        return result.get("secure_url")
    except Exception as e:
        logging.error(f"âŒ Cloudinary ä¸Šä¼ å¤±è´¥: {e}")
        return None

def _fetch_data(start_datetime: datetime, end_datetime: datetime) -> pd.DataFrame:
    try:
        engine = create_engine(DATABASE_URL)
        query = """
        SELECT username, name, content, timestamp, keyword, shift 
        FROM messages 
        WHERE timestamp BETWEEN %(start)s AND %(end)s
        """
        params = {
            "start": start_datetime.astimezone(pytz.UTC),
            "end": end_datetime.astimezone(pytz.UTC)
        }
        df_iter = pd.read_sql_query(query, engine, params=params, chunksize=50000)
        df = pd.concat(df_iter, ignore_index=True)
        logging.info(f"âœ… æ•°æ®è¯»å–å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
    except Exception as e:
        logging.error(f"âŒ æ— æ³•è¿æ¥æ•°æ®åº“æˆ–è¯»å–æ•°æ®: {e}")
        return pd.DataFrame()

    if df.empty:
        return df

    df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce", utc=True).dt.tz_convert(BEIJING_TZ)
    df = df.dropna(subset=["timestamp"]).copy()
    return df

def _mark_late_early(excel_path: str):
    """
    æ ‡æ³¨è¿Ÿåˆ°ï¼ˆçº¢è‰²+ç­æ¬¡æ ‡è¯†ï¼‰ã€æ—©é€€ï¼ˆçº¢è‰²+ç­æ¬¡æ ‡è¯†ï¼‰ã€è¡¥å¡ï¼ˆé»„è‰²+ç­æ¬¡æ ‡è¯†ï¼‰ã€‚
    æ”¯æŒè·¨å¤©ç­æ¬¡ï¼ˆå¦‚ Iç­æ¬¡æ—¥ä¸‹ç­ï¼‰ä»¥åŠå‡Œæ™¨ä¸‹ç­çš„æ­£å¸¸æ‰“å¡åˆ¤å®šã€‚
    """
    wb = load_workbook(excel_path)
    fill_red = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")      # æµ…çº¢
    fill_yellow = PatternFill(start_color="FFF2CC", end_color="FFF2CC", fill_type="solid")  # æµ…é»„

    for sheet in wb.worksheets:
        for row in sheet.iter_rows(min_row=2):  # è·³è¿‡è¡¨å¤´
            shift_cell, time_cell, keyword_cell = row[3], row[1], row[2]

            if not shift_cell.value or not time_cell.value:
                continue

            shift_text = str(shift_cell.value).strip()
            shift_name = re.split(r'[ï¼ˆ(]', shift_text)[0]  # æå–ç­æ¬¡åï¼ˆå¦‚ Iç­ï¼‰

            # æ—¶é—´è§£æï¼šå…¼å®¹ Excel datetime å¯¹è±¡æˆ–å­—ç¬¦ä¸²
            if isinstance(time_cell.value, datetime):
                dt = time_cell.value
            else:
                try:
                    dt = datetime.strptime(str(time_cell.value), "%Y-%m-%d %H:%M:%S")
                except Exception:
                    continue  # æ—¶é—´æ ¼å¼å¼‚å¸¸è·³è¿‡

            # 1ï¸âƒ£ è¡¥å¡æ ‡è®°ï¼ˆé»„è‰²ï¼‰
            if "è¡¥å¡" in shift_text:
                time_cell.fill = fill_yellow
                shift_cell.fill = fill_yellow
                if "ï¼ˆè¡¥å¡ï¼‰" not in shift_text:
                    shift_cell.value = f"{shift_text}ï¼ˆè¡¥å¡ï¼‰"
                continue

            # 2ï¸âƒ£ è¿Ÿåˆ°/æ—©é€€åˆ¤å®š
            if shift_name in SHIFT_TIMES:
                start_time, end_time = SHIFT_TIMES[shift_name]

                # ---- è¿Ÿåˆ°åˆ¤å®š ----
                if keyword_cell.value == "#ä¸Šç­æ‰“å¡":
                    if dt.time() > start_time:
                        time_cell.fill = fill_red
                        shift_cell.fill = fill_red
                        if "ï¼ˆè¿Ÿåˆ°ï¼‰" not in shift_text:
                            shift_cell.value = f"{shift_text}ï¼ˆè¿Ÿåˆ°ï¼‰"

                # ---- æ—©é€€åˆ¤å®š ----
                elif keyword_cell.value == "#ä¸‹ç­æ‰“å¡":
                    if shift_name == "Iç­":
                        # Iç­ï¼šæ¬¡æ—¥ 00:00 ä¸‹ç­æ­£å¸¸
                        if dt.hour == 0:
                            continue
                        # å½“å¤© 15:00-23:59 ä¸‹ç­ â†’ æ—©é€€
                        elif 15 <= dt.hour <= 23:
                            time_cell.fill = fill_red
                            shift_cell.fill = fill_red
                            if "ï¼ˆæ—©é€€ï¼‰" not in shift_text:
                                shift_cell.value = f"{shift_text}ï¼ˆæ—©é€€ï¼‰"
                    else:
                        # å…¶ä»–ç­æ¬¡ï¼šæ­£å¸¸ä¸‹ç­æ—¶é—´å†…åˆ¤å®šæ—©é€€
                        # å…è®¸å‡Œæ™¨ 0:00~1:00 æ­£å¸¸ä¸‹ç­ï¼ˆè·¨å¤©ï¼‰
                        if 0 <= dt.hour <= 1:
                            continue
                        if dt.time() < end_time:
                            time_cell.fill = fill_red
                            shift_cell.fill = fill_red
                            if "ï¼ˆæ—©é€€ï¼‰" not in shift_text:
                                shift_cell.value = f"{shift_text}ï¼ˆæ—©é€€ï¼‰"

    wb.save(excel_path)

def export_excel(start_datetime: datetime, end_datetime: datetime):
    df = _fetch_data(start_datetime, end_datetime)
    if df.empty:
        logging.warning("âš ï¸ æŒ‡å®šæ—¥æœŸå†…æ²¡æœ‰æ•°æ®")
        return None

    # æ·»åŠ æ—¥æœŸåˆ—
    df["date"] = df["timestamp"].dt.strftime("%Y-%m-%d")

    start_str = start_datetime.strftime("%Y-%m-%d")
    end_str = (end_datetime - pd.Timedelta(seconds=1)).strftime("%Y-%m-%d")

    export_dir = os.path.join(DATA_DIR, f"excel_{start_str}_{end_str}")
    os.makedirs(export_dir, exist_ok=True)
    excel_path = os.path.join(export_dir, f"æ‰“å¡è®°å½•_{start_str}_{end_str}.xlsx")

    # æ ¼å¼åŒ–ç­æ¬¡å‡½æ•°
    def format_shift(shift):
        if pd.isna(shift):
            return shift
        shift_text = str(shift)
        if re.search(r'ï¼ˆ\d{2}:\d{2}-\d{2}:\d{2}ï¼‰', shift_text):
            return shift_text
        shift_name = shift_text.split("ï¼ˆ")[0]
        if shift_name in SHIFT_TIMES:
            start, end = SHIFT_TIMES[shift_name]
            end_str = end.strftime('%H:%M')
            return f"{shift_text}ï¼ˆ{start.strftime('%H:%M')}-{end_str}ï¼‰"
        return shift_text

    # å†™å…¥ Excelï¼šæ¯ä¸ªæ—¥æœŸä¸€ä¸ª Sheet
    with pd.ExcelWriter(excel_path, engine="openpyxl") as writer:
        for day, group_df in df.groupby("date"):
            slim_df = group_df[["name", "timestamp", "keyword", "shift"]].sort_values("timestamp").copy()
            slim_df.columns = ["å§“å", "æ‰“å¡æ—¶é—´", "å…³é”®è¯", "ç­æ¬¡"]
            slim_df["æ‰“å¡æ—¶é—´"] = slim_df["æ‰“å¡æ—¶é—´"].dt.strftime("%Y-%m-%d %H:%M:%S")
            slim_df["ç­æ¬¡"] = slim_df["ç­æ¬¡"].apply(format_shift)
            slim_df.to_excel(writer, sheet_name=day[:31], index=False)

    # æ ‡æ³¨è¿Ÿåˆ°/æ—©é€€å’Œè¡¥å¡
    _mark_late_early(excel_path)

    # åŠ è½½ Excel ä»¥ä¾¿åç»­ä¿®æ”¹
    wb = load_workbook(excel_path)

    # -------------------- ç”Ÿæˆç»Ÿè®¡ Sheet --------------------
    stats = []
    for sheet in wb.worksheets:
        if sheet.title == "ç»Ÿè®¡":
            continue
        for row in sheet.iter_rows(min_row=2, values_only=True):
            name, _, keyword, shift_text = row
            if not name or not keyword or not shift_text:
                continue
            shift_str = str(shift_text)
            if "è¡¥å¡" in shift_str:
                status = "è¡¥å¡"
            elif "è¿Ÿåˆ°" in shift_str or "æ—©é€€" in shift_str:
                status = "è¿Ÿåˆ°/æ—©é€€"
            else:
                status = "æ­£å¸¸"
            stats.append({"å§“å": name, "çŠ¶æ€": status})

    stats_df = pd.DataFrame(stats)
    if not stats_df.empty:
        summary_df = stats_df.groupby(["å§“å", "çŠ¶æ€"]).size().unstack(fill_value=0).reset_index()

        # ç¡®ä¿åˆ—å­˜åœ¨
        for col in ["æ­£å¸¸", "è¿Ÿåˆ°/æ—©é€€", "è¡¥å¡"]:
            if col not in summary_df.columns:
                summary_df[col] = 0

        # è®¡ç®—â€œå¼‚å¸¸æ€»æ•°â€
        summary_df["å¼‚å¸¸æ€»æ•°"] = summary_df["è¿Ÿåˆ°/æ—©é€€"] + summary_df["è¡¥å¡"]

        # âœ… æŒ‰â€œæ­£å¸¸æ‰“å¡æ¬¡æ•°â€é™åºæ’åº
        summary_df = summary_df.sort_values(by="æ­£å¸¸", ascending=False)

        # è°ƒæ•´åˆ—é¡ºåº
        summary_df = summary_df[["å§“å", "æ­£å¸¸", "è¿Ÿåˆ°/æ—©é€€", "è¡¥å¡", "å¼‚å¸¸æ€»æ•°"]]

        # åˆ›å»ºç»Ÿè®¡ Sheet
        stats_sheet = wb.create_sheet("ç»Ÿè®¡", 0)
        headers = ["å§“å", "æ­£å¸¸æ‰“å¡", "è¿Ÿåˆ°/æ—©é€€", "è¡¥å¡", "å¼‚å¸¸æ€»æ•°"]
        for r_idx, row in enumerate([headers] + summary_df.values.tolist(), 1):
            for c_idx, value in enumerate(row, 1):
                stats_sheet.cell(row=r_idx, column=c_idx, value=value)

        # âœ… è¡¨å¤´æ ·å¼ï¼šåŠ ç²—ã€å±…ä¸­ã€å†»ç»“é¦–è¡Œ
        from openpyxl.styles import Font, Alignment, PatternFill
        stats_sheet.freeze_panes = "A2"
        for cell in stats_sheet[1]:
            cell.font = Font(bold=True)
            cell.alignment = Alignment(horizontal="center")

        # âœ… å¼‚å¸¸æ€»æ•° â‰¥ 3 é«˜äº®çº¢è‰²æ•´è¡Œ
        fill_red = PatternFill(start_color="F8CBAD", end_color="F8CBAD", fill_type="solid")
        for r_idx in range(2, stats_sheet.max_row + 1):
            abnormal = stats_sheet.cell(row=r_idx, column=5).value  # å¼‚å¸¸æ€»æ•°åˆ—
            if abnormal is not None and abnormal >= 3:
                for c_idx in range(1, 6):
                    stats_sheet.cell(row=r_idx, column=c_idx).fill = fill_red

    # -------------------- æ‰€æœ‰ Sheet æ ·å¼è®¾ç½® --------------------
    from openpyxl.styles import Font, Alignment
    for sheet in wb.worksheets:
        sheet.freeze_panes = "A2"
        for cell in sheet[1]:
            cell.font = Font(bold=True)
            cell.alignment = Alignment(horizontal="center")

        # è‡ªåŠ¨åˆ—å®½ + å…¨éƒ¨æ–‡å­—å±…ä¸­
        for col in sheet.columns:
            max_length = 0
            col_letter = col[0].column_letter
            for cell in col:
                try:
                    length = len(str(cell.value)) if cell.value is not None else 0
                    if length > max_length:
                        max_length = length
                    cell.alignment = Alignment(horizontal="center", vertical="center")  # âœ… æ‰€æœ‰å•å…ƒæ ¼æ–‡å­—å±…ä¸­
                except:
                    pass
            sheet.column_dimensions[col_letter].width = max_length + 2

    wb.save(excel_path)
    logging.info(f"âœ… Excel å¯¼å‡ºå®Œæˆï¼ˆå«è‡ªåŠ¨åˆ—å®½ã€æ­£å¸¸æ‰“å¡æ’åºã€å¼‚å¸¸é«˜äº®ã€æ–‡å­—å±…ä¸­ï¼‰: {excel_path}")
    return excel_path

def export_images(start_datetime: datetime, end_datetime: datetime, max_zip_size_mb: int = 40):
    """
    å¯¼å‡ºæŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ‰€æœ‰å›¾ç‰‡ï¼Œé»˜è®¤æœ¬æœˆï¼ŒæŒ‰å¤§å°åˆ†åŒ…ï¼ˆæ¯åŒ… 40MBï¼‰
    è¿”å›ï¼šlist[str] -> æ¯åŒ…ä¸€ä¸ª ZIP æ–‡ä»¶è·¯å¾„
    """
    try:
        df = _fetch_data(start_datetime, end_datetime)
        if df.empty:
            logging.warning("âš ï¸ æŒ‡å®šæ—¥æœŸå†…æ²¡æœ‰æ•°æ®")
            return None

        # ä»…ç­›é€‰å›¾ç‰‡ URL
        photo_df = df[df["content"].str.contains(r"\.(?:jpg|jpeg|png|gif)$", case=False, na=False)].copy()
        if photo_df.empty:
            logging.warning("âš ï¸ æŒ‡å®šæ—¥æœŸå†…æ²¡æœ‰å›¾ç‰‡ã€‚")
            return None

        start_str = start_datetime.strftime("%Y-%m-%d")
        end_str = (end_datetime - pd.Timedelta(seconds=1)).strftime("%Y-%m-%d")

        export_dir = os.path.join(DATA_DIR, f"images_{start_str}_{end_str}")
        if os.path.exists(export_dir):
            shutil.rmtree(export_dir)
        os.makedirs(export_dir, exist_ok=True)

        # ä¸´æ—¶ä¸‹è½½æ–‡ä»¶å¤¹
        download_dir = os.path.join(export_dir, "downloads")
        os.makedirs(download_dir, exist_ok=True)

        # å¹¶å‘ä¸‹è½½æ‰€æœ‰å›¾ç‰‡
        logging.info(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½å›¾ç‰‡ï¼Œå…± {len(photo_df)} å¼ ")
        def download_image(url, filename):
            try:
                r = requests.get(url, stream=True, timeout=15)
                if r.status_code == 200:
                    with open(filename, "wb") as f:
                        shutil.copyfileobj(r.raw, f)
                    return True
                else:
                    logging.warning(f"âš ï¸ ä¸‹è½½å¤±è´¥ï¼ˆçŠ¶æ€ç  {r.status_code}ï¼‰: {url}")
            except Exception as e:
                logging.warning(f"âš ï¸ ä¸‹è½½å¤±è´¥: {url} ({e})")
            return False

        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = []
            for _, row in photo_df.iterrows():
                url = row["content"]
                filename = safe_filename(f"{row['name']}_{row['timestamp'].strftime('%Y%m%d_%H%M%S')}{os.path.splitext(url)[-1]}")
                file_path = os.path.join(download_dir, filename)
                futures.append(executor.submit(download_image, url, file_path))
            for future in futures:
                future.result()

        # ---------------- æŒ‰å¤§å°åˆ†åŒ… ----------------
        zip_paths = []
        current_zip_files = []
        current_zip_size = 0
        zip_index = 1

        def create_zip(files, index):
            zip_name = f"å›¾ç‰‡_{start_str}_to_{end_str}_åŒ…{index}.zip"
            zip_path = os.path.join(export_dir, zip_name)
            with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zf:
                for f in files:
                    zf.write(f, arcname=os.path.basename(f))
            logging.info(f"âœ… ç”Ÿæˆ ZIP: {zip_path}")
            return zip_path

        for file in sorted(os.listdir(download_dir)):
            file_path = os.path.join(download_dir, file)
            file_size = os.path.getsize(file_path)
            if current_zip_size + file_size > max_zip_size_mb * 1024 * 1024:
                # æ‰“åŒ…å½“å‰æ–‡ä»¶é›†å¹¶é‡ç½®
                if current_zip_files:
                    zip_paths.append(create_zip(current_zip_files, zip_index))
                    zip_index += 1
                    current_zip_files = []
                    current_zip_size = 0
            current_zip_files.append(file_path)
            current_zip_size += file_size

        # æ‰“åŒ…æœ€åä¸€åŒ…
        if current_zip_files:
            zip_paths.append(create_zip(current_zip_files, zip_index))

        shutil.rmtree(download_dir)  # æ¸…ç†ä¸‹è½½æ–‡ä»¶
        logging.info(f"âœ… å›¾ç‰‡æ‰“åŒ…å®Œæˆï¼Œå…± {len(zip_paths)} åŒ…")
        return zip_paths

    except Exception as e:
        logging.error(f"âŒ export_images å¤±è´¥: {e}")
        return None

