import os
import re
import pandas as pd
import pytz
import shutil
import zipfile
import requests
import logging
from datetime import datetime
from sqlalchemy import create_engine
from concurrent.futures import ThreadPoolExecutor
from config import DATA_DIR, DATABASE_URL
import cloudinary
import cloudinary.uploader

# æ—¥å¿—é…ç½®
logging.basicConfig(level=logging.WARNING, format="[%(asctime)s] %(levelname)s: %(message)s")

MAX_TELEGRAM_FILE_MB = 50  # Telegram æ–‡ä»¶é™åˆ¶

def safe_filename(name: str) -> str:
    """æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
    return re.sub(r'[\\/*?:"<>|]', "_", str(name))

def export_messages(start_datetime, end_datetime):
    if not isinstance(start_datetime, datetime) or not isinstance(end_datetime, datetime):
        logging.error("âŒ å‚æ•°å¿…é¡»ä¸º datetime ç±»å‹")
        return None

    try:
        engine = create_engine(DATABASE_URL)
        query = "SELECT username, name, content, timestamp, keyword, shift FROM messages"
        df_iter = pd.read_sql_query(query, engine, chunksize=50000)  # åˆ†æ‰¹åŠ è½½
        df = pd.concat(df_iter, ignore_index=True)
        logging.info(f"âœ… æ•°æ®è¯»å–å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
    except Exception as e:
        logging.error(f"âŒ æ— æ³•è¿æ¥æ•°æ®åº“æˆ–è¯»å–æ•°æ®: {e}")
        return None

    # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
    if 'timestamp' not in df.columns:
        logging.error("âŒ æ•°æ®ä¸­ä¸å« timestamp å­—æ®µ")
        return None
    if 'name' not in df.columns:
        df['name'] = None
    if 'shift' not in df.columns:
        df['shift'] = None

    # å¤„ç†æ—¶é—´å­—æ®µå¹¶è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
    df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce", utc=True)
    df = df.dropna(subset=["timestamp"]).copy()
    df["timestamp"] = df["timestamp"].dt.tz_convert("Asia/Shanghai")

    # è¿‡æ»¤æ—¶é—´èŒƒå›´
    filtered = df[(df["timestamp"] >= start_datetime) & (df["timestamp"] < end_datetime)].copy()
    if filtered.empty:
        logging.warning("âš ï¸ æŒ‡å®šæ—¥æœŸå†…æ²¡æœ‰æ•°æ®")
        return None

    # ç”Ÿæˆå¯¼å‡ºè·¯å¾„
    start_str = start_datetime.strftime("%Y-%m-%d")
    end_str = (end_datetime - pd.Timedelta(seconds=1)).strftime("%Y-%m-%d")
    export_dir = os.path.join(DATA_DIR, f"export_{start_str}_{end_str}")
    os.makedirs(export_dir, exist_ok=True)

    # âœ… Excel å¯¼å‡º
    filtered["date"] = filtered["timestamp"].dt.strftime("%Y-%m-%d")
    excel_path = os.path.join(export_dir, f"æ‰“å¡è®°å½•_{start_str}_{end_str}.xlsx")
    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
        for day, group_df in filtered.groupby("date"):
            slim_df = group_df[["name", "timestamp", "keyword", "shift"]].sort_values("timestamp").copy()
            slim_df.columns = ["å§“å", "æ‰“å¡æ—¶é—´", "å…³é”®è¯", "ç­æ¬¡"]
            slim_df["æ‰“å¡æ—¶é—´"] = slim_df["æ‰“å¡æ—¶é—´"].dt.strftime("%Y-%m-%d %H:%M:%S")
            slim_df.to_excel(writer, sheet_name=day[:31], index=False)
    logging.info(f"âœ… Excel å¯¼å‡ºå®Œæˆ: {excel_path}")

    # âœ… ä¸‹è½½å›¾ç‰‡ï¼ˆæŒ‰å¤©å½’ç±»ï¼‰
    image_dir = os.path.join(export_dir, "å›¾ç‰‡")
    os.makedirs(image_dir, exist_ok=True)
    photo_df = filtered[filtered["content"].str.endswith(".jpg", na=False)]

    def download_image(row):
        url = row.get("content")
        if url and url.startswith("http"):
            try:
                ts = row["timestamp"].strftime("%Y-%m-%d_%H-%M-%S")
                date_folder = row["timestamp"].strftime("%Y-%m-%d")
                day_dir = os.path.join(image_dir, date_folder)
                os.makedirs(day_dir, exist_ok=True)

                name = safe_filename(row["name"] or "åŒ¿å")
                keyword = safe_filename(row["keyword"] or "æ— å…³é”®è¯")
                filename = f"{ts}_{name}_{keyword}.jpg"
                save_path = os.path.join(day_dir, filename)

                response = requests.get(url, stream=True, timeout=10)
                if response.status_code == 200:
                    with open(save_path, "wb") as f:
                        for chunk in response.iter_content(1024):
                            f.write(chunk)
                logging.info(f"ğŸ“¥ ä¸‹è½½æˆåŠŸ: {filename}")
            except Exception as e:
                logging.warning(f"[å›¾ç‰‡ä¸‹è½½å¤±è´¥] {url} - {e}")

    with ThreadPoolExecutor(max_workers=8) as executor:
        executor.map(download_image, [row for _, row in photo_df.iterrows()])

    # âœ… æ‰“åŒ… ZIP
    zip_path = os.path.join(DATA_DIR, f"è€ƒå‹¤ç»Ÿè®¡_{start_str}_{end_str}.zip")
    with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zipf:
        for root, _, files in os.walk(export_dir):
            for file in files:
                full_path = os.path.join(root, file)
                arcname = os.path.relpath(full_path, export_dir)
                zipf.write(full_path, arcname)
    logging.info(f"âœ… æ–‡ä»¶æ‰“åŒ…å®Œæˆ: {zip_path}")

    # âœ… æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤¹
    try:
        shutil.rmtree(export_dir)
    except Exception as e:
        logging.warning(f"[æ¸…ç†å¯¼å‡ºç›®å½•å¤±è´¥] {e}")

    # âœ… æ£€æŸ¥æ–‡ä»¶å¤§å°å¹¶ä¸Šä¼ åˆ° Cloudinary
    file_size_mb = os.path.getsize(zip_path) / (1024 * 1024)
    if file_size_mb > MAX_TELEGRAM_FILE_MB:
        logging.warning(f"âš ï¸ æ–‡ä»¶è¶…è¿‡ {MAX_TELEGRAM_FILE_MB}MBï¼Œå°è¯•ä¸Šä¼ åˆ° Cloudinary...")
        url = upload_to_cloudinary(zip_path)
        if url:
            logging.info(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {url}")
            return url
        else:
            logging.error("âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥")
            return None

    logging.info(f"âœ… å¯¼å‡ºå®Œæˆï¼Œæœ¬åœ°æ–‡ä»¶: {zip_path}")
    return zip_path

def upload_to_cloudinary(file_path: str) -> str | None:
    """ä¸Šä¼ æ–‡ä»¶åˆ° Cloudinary å¹¶è¿”å›ä¸‹è½½é“¾æ¥"""
    try:
        result = cloudinary.uploader.upload(
            file_path,
            resource_type="raw",
            folder="telegram_exports",
            public_id=os.path.splitext(os.path.basename(file_path))[0]  # ç”¨æ–‡ä»¶åä½œä¸º ID
        )
        secure_url = result.get("secure_url")
        if secure_url:
            logging.info(f"âœ… Cloudinary ä¸Šä¼ æˆåŠŸ: {secure_url}")
            return secure_url
        else:
            logging.error("âŒ Cloudinary ä¸Šä¼ æœªè¿”å› secure_url")
            return None
    except Exception as e:
        logging.error(f"âŒ Cloudinary ä¸Šä¼ å¤±è´¥: {e}")
        return None
