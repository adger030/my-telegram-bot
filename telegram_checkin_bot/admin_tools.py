from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes
from sqlalchemy import text
import cloudinary.api
import os
from datetime import datetime, timedelta
from collections import defaultdict
from dateutil.parser import parse
from db_pg import engine, get_user_logs, get_user_logs_by_name
from config import ADMIN_IDS, BEIJING_TZ, SHIFT_TIMES, LOGS_PER_PAGE

# æå– Cloudinary public_id
def extract_cloudinary_public_id(url: str) -> str | None:
    """
    æå– Cloudinary public_idï¼Œæ”¯æŒå¤šçº§ç›®å½•ã€‚
    e.g. https://res.cloudinary.com/demo/image/upload/v123456/folder/image.jpg
         -> folder/image
    """
    if "cloudinary.com" not in url:
        return None
    try:
        # å»æ‰ query å‚æ•°
        url = url.split("?")[0]
        parts = url.split("/upload/")
        if len(parts) < 2:
            return None
        path = parts[1]
        # å»æ‰ç‰ˆæœ¬å· vXXXX
        path_parts = path.split("/")
        if path_parts[0].startswith("v") and path_parts[0][1:].isdigit():
            path_parts = path_parts[1:]
        public_id_with_ext = "/".join(path_parts)
        public_id = os.path.splitext(public_id_with_ext)[0]
        return public_id
    except Exception as e:
        print(f"âš ï¸ public_id æå–å¤±è´¥: {url} -> {e}")
        return None

# æ‰¹é‡åˆ é™¤ Cloudinary
def batch_delete_cloudinary(public_ids: list, batch_size=100):
    deleted_total = 0
    for i in range(0, len(public_ids), batch_size):
        batch = public_ids[i:i + batch_size]
        try:
            response = cloudinary.api.delete_resources(batch)
            deleted = response.get("deleted", {})
            failed = response.get("failed", {})

            deleted_total += sum(1 for v in deleted.values() if v == "deleted")

            for pid, error in failed.items():
                print(f"âš ï¸ åˆ é™¤å¤±è´¥: {pid} - {error}")
        except Exception as e:
            print(f"âŒ æ‰¹é‡åˆ é™¤å¤±è´¥: {e}")
    return deleted_total

# ç®¡ç†å‘˜åˆ é™¤å‘½ä»¤
async def delete_range_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_user.id not in ADMIN_IDS:
        await update.message.reply_text("â›” æ— æƒé™ï¼ä»…ç®¡ç†å‘˜å¯æ‰§è¡Œæ­¤å‘½ä»¤ã€‚")
        return

    args = context.args
    if len(args) not in (2, 3):
        await update.message.reply_text("âš ï¸ ç”¨æ³•ï¼š/delete_range YYYY-MM-DD YYYY-MM-DD [confirm]")
        return

    start_date, end_date = args[0], args[1]
    confirm = len(args) == 3 and args[2].lower() == "confirm"

    # æŸ¥è¯¢è®°å½•
    with engine.begin() as conn:
        result = conn.execute(
            text("""
                SELECT id, content FROM messages
                WHERE timestamp >= :start_date AND timestamp <= :end_date
            """),
            {"start_date": f"{start_date} 00:00:00", "end_date": f"{end_date} 23:59:59"}
        )
        rows = result.fetchall()

    total_count = len(rows)
    image_urls = [r[1] for r in rows if r[1] and "cloudinary.com" in r[1]]
    public_ids = [extract_cloudinary_public_id(url) for url in image_urls if extract_cloudinary_public_id(url)]

    if not confirm:
        await update.message.reply_text(
            f"ğŸ” é¢„è§ˆåˆ é™¤èŒƒå›´ï¼š{start_date} è‡³ {end_date}\n"
            f"ğŸ“„ å…± {total_count} æ¡è®°å½•ï¼Œå…¶ä¸­ {len(public_ids)} å¼ å›¾ç‰‡ã€‚\n\n"
            f"è¦ç¡®è®¤åˆ é™¤ï¼Œè¯·ä½¿ç”¨ï¼š\n`/delete_range {start_date} {end_date} confirm`",
            parse_mode="Markdown"
        )
        return

    # åˆ é™¤ Cloudinary å›¾ç‰‡
    deleted_images = batch_delete_cloudinary(public_ids)

    # åˆ é™¤æ•°æ®åº“è®°å½•
    with engine.begin() as conn:
        delete_result = conn.execute(
            text("""
                DELETE FROM messages
                WHERE timestamp >= :start_date AND timestamp <= :end_date
                RETURNING id
            """),
            {"start_date": f"{start_date} 00:00:00", "end_date": f"{end_date} 23:59:59"}
        )
        deleted_count = len(delete_result.fetchall())

    await update.message.reply_text(
        f"âœ… åˆ é™¤å®Œæˆï¼\n\n"
        f"ğŸ“„ æ•°æ®åº“è®°å½•ï¼š{deleted_count}/{total_count} æ¡\n"
        f"ğŸ–¼ Cloudinary å›¾ç‰‡ï¼š{deleted_images}/{len(public_ids)} å¼ \n"
        f"ğŸ“… èŒƒå›´ï¼š{start_date} ~ {end_date}"
    )


async def userlogs_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_user.id not in ADMIN_IDS:
        await update.message.reply_text("â›” æ— æƒé™ï¼Œä»…ç®¡ç†å‘˜å¯æŸ¥çœ‹ä»–äººè®°å½•ã€‚")
        return

    if not context.args:
        await update.message.reply_text("âš ï¸ ç”¨æ³•ï¼š/userlogs @ç”¨æˆ·å æˆ– /userlogs ä¸­æ–‡å§“å")
        return

    # 1ï¸âƒ£ è§£ææŸ¥è¯¢å¯¹è±¡
    raw_input = context.args[0]
    is_username = raw_input.startswith("@")
    target_key = raw_input.lstrip("@") if is_username else raw_input

    # 2ï¸âƒ£ è®¡ç®—æœ¬æœˆæ—¶é—´èŒƒå›´
    now = datetime.now(BEIJING_TZ)
    start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
    end = (start + timedelta(days=32)).replace(day=1)

    # 3ï¸âƒ£ è·å–è®°å½•
    if is_username:
        logs = get_user_logs(target_key, start, end)
    else:
        logs = get_user_logs_by_name(target_key, start, end)

    if not logs:
        await update.message.reply_text(f"ğŸ“­ ç”¨æˆ· {target_key} æœ¬æœˆæš‚æ— æ‰“å¡è®°å½•ã€‚")
        return

    # 4ï¸âƒ£ è½¬æ¢æ—¶åŒº & æ’åº
    logs = [(parse(ts) if isinstance(ts, str) else ts, kw, shift) for ts, kw, shift in logs]
    logs = [(ts.astimezone(BEIJING_TZ), kw, shift) for ts, kw, shift in logs]
    logs = sorted(logs, key=lambda x: x[0])

    # 5ï¸âƒ£ æŒ‰å¤©ç»„åˆä¸Šä¸‹ç­æ‰“å¡
    daily_map = defaultdict(dict)
    i = 0
    while i < len(logs):
        ts, kw, shift = logs[i]
        date_key = ts.date()
        if kw == "#ä¸‹ç­æ‰“å¡" and ts.hour < 6:
            date_key = (ts - timedelta(days=1)).date()

        if kw == "#ä¸Šç­æ‰“å¡":
            daily_map[date_key]["shift"] = shift
            daily_map[date_key]["#ä¸Šç­æ‰“å¡"] = ts
            j = i + 1
            while j < len(logs):
                ts2, kw2, _ = logs[j]
                if kw2 == "#ä¸‹ç­æ‰“å¡" and timedelta(0) < (ts2 - ts) <= timedelta(hours=12):
                    daily_map[date_key]["#ä¸‹ç­æ‰“å¡"] = ts2
                    break
                j += 1
            i = j if j > i else i + 1
        else:
            daily_map[date_key]["#ä¸‹ç­æ‰“å¡"] = ts
            i += 1

    # 6ï¸âƒ£ ç»Ÿè®¡
    total_complete = total_abnormal = total_makeup = 0
    for day, kw_map in daily_map.items():
        shift_full = kw_map.get("shift", "æœªé€‰æ‹©ç­æ¬¡")
        is_makeup = shift_full.endswith("ï¼ˆè¡¥å¡ï¼‰")
        shift_name = shift_full.split("ï¼ˆ")[0]
        has_up = "#ä¸Šç­æ‰“å¡" in kw_map
        has_down = "#ä¸‹ç­æ‰“å¡" in kw_map
        has_late = has_early = False

        if is_makeup:
            total_makeup += 1

        if has_up and shift_name in SHIFT_TIMES:
            start_time, _ = SHIFT_TIMES[shift_name]
            if kw_map["#ä¸Šç­æ‰“å¡"].time() > start_time:
                has_late = True

        if has_down and shift_name in SHIFT_TIMES:
            _, end_time = SHIFT_TIMES[shift_name]
            down_ts = kw_map["#ä¸‹ç­æ‰“å¡"]
            if shift_name == "Iç­" and down_ts.date() == day:
                has_early = True
            elif shift_name != "Iç­" and down_ts.time() < end_time:
                has_early = True

        if is_makeup:
            continue
        if has_late:
            total_abnormal += 1
        if has_early:
            total_abnormal += 1
        if not has_late and not has_early and (has_up or has_down):
            total_complete += 2 if has_up and has_down else 1

    # 7ï¸âƒ£ åˆ†é¡µ
    all_days = sorted(daily_map)
    pages = [all_days[i:i + LOGS_PER_PAGE] for i in range(0, len(all_days), LOGS_PER_PAGE)]
    context.user_data["userlogs_pages"] = {
        "pages": pages,
        "daily_map": daily_map,
        "page_index": 0,
        "summary": (total_complete, total_abnormal, total_makeup),
        "target_username": target_key,  # æ— è®ºæ˜¯ username è¿˜æ˜¯ nameï¼Œéƒ½è®°å½•
        "is_username": is_username      # è®°å½•æŸ¥è¯¢æ–¹å¼
    }

    await send_userlogs_page(update, context)  # å±•ç¤ºç¬¬ä¸€é¡µ


# ===========================
# å‘é€åˆ†é¡µå†…å®¹
# ===========================
async def send_userlogs_page(update: Update, context: ContextTypes.DEFAULT_TYPE):
    data = context.user_data["userlogs_pages"]
    pages, daily_map, page_index = data["pages"], data["daily_map"], data["page_index"]
    total_complete, total_abnormal, total_makeup = data["summary"]
    target_username = data["target_username"]

    current_page_days = pages[page_index]
    reply = f"ğŸ—“ï¸ {target_username} æœ¬æœˆæ‰“å¡è®°å½•ï¼ˆç¬¬ {page_index+1}/{len(pages)} é¡µï¼‰ï¼š\n\n"

    for idx, day in enumerate(current_page_days, start=1 + page_index * LOGS_PER_PAGE):
        kw_map = daily_map[day]
        shift_full = kw_map.get("shift", "æœªé€‰æ‹©ç­æ¬¡")
        is_makeup = shift_full.endswith("ï¼ˆè¡¥å¡ï¼‰")
        shift_name = shift_full.split("ï¼ˆ")[0]
        has_up = "#ä¸Šç­æ‰“å¡" in kw_map
        has_down = "#ä¸‹ç­æ‰“å¡" in kw_map
        has_late = has_early = False

        if has_up and shift_name in SHIFT_TIMES:
            start_time, _ = SHIFT_TIMES[shift_name]
            if kw_map["#ä¸Šç­æ‰“å¡"].time() > start_time:
                has_late = True

        if has_down and shift_name in SHIFT_TIMES:
            _, end_time = SHIFT_TIMES[shift_name]
            down_ts = kw_map["#ä¸‹ç­æ‰“å¡"]
            if shift_name == "Iç­" and down_ts.date() == day:
                has_early = True
            elif shift_name != "Iç­" and down_ts.time() < end_time:
                has_early = True

        reply += f"{idx}. {day.strftime('%mæœˆ%dæ—¥')} - {shift_name}\n"
        if has_up:
            reply += f"   â””â”€ #ä¸Šç­æ‰“å¡ï¼š{kw_map['#ä¸Šç­æ‰“å¡'].strftime('%H:%M')}{'ï¼ˆè¡¥å¡ï¼‰' if is_makeup else ''}{'ï¼ˆè¿Ÿåˆ°ï¼‰' if has_late else ''}\n"
        if has_down:
            down_ts = kw_map["#ä¸‹ç­æ‰“å¡"]
            next_day = down_ts.date() > day
            reply += f"   â””â”€ #ä¸‹ç­æ‰“å¡ï¼š{down_ts.strftime('%H:%M')}{'ï¼ˆæ¬¡æ—¥ï¼‰' if next_day else ''}{'ï¼ˆæ—©é€€ï¼‰' if has_early else ''}\n"

    reply += (
        f"\nğŸŸ¢ æ­£å¸¸ï¼š{total_complete} æ¬¡\n"
        f"ğŸ”´ å¼‚å¸¸ï¼ˆè¿Ÿåˆ°/æ—©é€€ï¼‰ï¼š{total_abnormal} æ¬¡\n"
        f"ğŸŸ¡ è¡¥å¡ï¼š{total_makeup} æ¬¡"
    )

    # åˆ†é¡µæŒ‰é’®
    buttons = []
    if page_index > 0:
        buttons.append(InlineKeyboardButton("â¬… ä¸Šä¸€é¡µ", callback_data="userlogs_prev"))
    if page_index < len(pages) - 1:
        buttons.append(InlineKeyboardButton("â¡ ä¸‹ä¸€é¡µ", callback_data="userlogs_next"))
    markup = InlineKeyboardMarkup([buttons]) if buttons else None

    if update.callback_query:
        await update.callback_query.edit_message_text(reply, reply_markup=markup)
    else:
        await update.message.reply_text(reply, reply_markup=markup)

# ===========================
# åˆ†é¡µæŒ‰é’®å›è°ƒ
# ===========================
async def userlogs_page_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()

    if "userlogs_pages" not in context.user_data:
        await query.edit_message_text("âš ï¸ ä¼šè¯å·²è¿‡æœŸï¼Œè¯·é‡æ–°ä½¿ç”¨ /userlogs")
        return

    if query.data == "userlogs_prev":
        context.user_data["userlogs_pages"]["page_index"] -= 1
    elif query.data == "userlogs_next":
        context.user_data["userlogs_pages"]["page_index"] += 1

    await send_userlogs_page(update, context)
