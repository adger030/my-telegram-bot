from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes
from sqlalchemy import text
import cloudinary.api
import os
from datetime import datetime, timedelta
from collections import defaultdict
from dateutil.parser import parse
from db_pg import engine, get_user_logs, get_user_logs_by_name
from config import ADMIN_IDS, BEIJING_TZ, SHIFT_TIMES, LOGS_PER_PAGE, DATA_DIR
from export import export_excel, export_images
import pandas as pd
import shutil

# æå– Cloudinary public_id
def extract_cloudinary_public_id(url: str) -> str | None:
    """
    æå– Cloudinary public_idï¼Œæ”¯æŒå¤šçº§ç›®å½•ã€‚
    e.g. https://res.cloudinary.com/demo/image/upload/v123456/folder/image.jpg
         -> folder/image
    """
    if "cloudinary.com" not in url:
        return None
    try:
        # å»æ‰ query å‚æ•°
        url = url.split("?")[0]
        parts = url.split("/upload/")
        if len(parts) < 2:
            return None
        path = parts[1]
        # å»æ‰ç‰ˆæœ¬å· vXXXX
        path_parts = path.split("/")
        if path_parts[0].startswith("v") and path_parts[0][1:].isdigit():
            path_parts = path_parts[1:]
        public_id_with_ext = "/".join(path_parts)
        public_id = os.path.splitext(public_id_with_ext)[0]
        return public_id
    except Exception as e:
        print(f"âš ï¸ public_id æå–å¤±è´¥: {url} -> {e}")
        return None

# æ‰¹é‡åˆ é™¤ Cloudinary
def batch_delete_cloudinary(public_ids: list, batch_size=100):
    deleted_total = 0
    for i in range(0, len(public_ids), batch_size):
        batch = public_ids[i:i + batch_size]
        try:
            response = cloudinary.api.delete_resources(batch)
            deleted = response.get("deleted", {})
            failed = response.get("failed", {})

            deleted_total += sum(1 for v in deleted.values() if v == "deleted")

            for pid, error in failed.items():
                print(f"âš ï¸ åˆ é™¤å¤±è´¥: {pid} - {error}")
        except Exception as e:
            print(f"âŒ æ‰¹é‡åˆ é™¤å¤±è´¥: {e}")
    return deleted_total

# ç®¡ç†å‘˜åˆ é™¤å‘½ä»¤
async def delete_range_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_user.id not in ADMIN_IDS:
        await update.message.reply_text("â›” æ— æƒé™ï¼ä»…ç®¡ç†å‘˜å¯æ‰§è¡Œæ­¤å‘½ä»¤ã€‚")
        return

    args = context.args
    if len(args) not in (2, 3):
        await update.message.reply_text("âš ï¸ ç”¨æ³•ï¼š/delete_range YYYY-MM-DD YYYY-MM-DD [confirm]")
        return

    start_date, end_date = args[0], args[1]
    confirm = len(args) == 3 and args[2].lower() == "confirm"

    # æŸ¥è¯¢è®°å½•
    with engine.begin() as conn:
        result = conn.execute(
            text("""
                SELECT id, content FROM messages
                WHERE timestamp >= :start_date AND timestamp <= :end_date
            """),
            {"start_date": f"{start_date} 00:00:00", "end_date": f"{end_date} 23:59:59"}
        )
        rows = result.fetchall()

    total_count = len(rows)
    image_urls = [r[1] for r in rows if r[1] and "cloudinary.com" in r[1]]
    public_ids = [extract_cloudinary_public_id(url) for url in image_urls if extract_cloudinary_public_id(url)]

    if not confirm:
        await update.message.reply_text(
            f"ğŸ” é¢„è§ˆåˆ é™¤èŒƒå›´ï¼š{start_date} è‡³ {end_date}\n"
            f"ğŸ“„ å…± {total_count} æ¡è®°å½•ï¼Œå…¶ä¸­ {len(public_ids)} å¼ å›¾ç‰‡ã€‚\n\n"
            f"è¦ç¡®è®¤åˆ é™¤ï¼Œè¯·ä½¿ç”¨ï¼š\n`/delete_range {start_date} {end_date} confirm`",
            parse_mode="Markdown"
        )
        return

    # åˆ é™¤ Cloudinary å›¾ç‰‡
    deleted_images = batch_delete_cloudinary(public_ids)

    # åˆ é™¤æ•°æ®åº“è®°å½•
    with engine.begin() as conn:
        delete_result = conn.execute(
            text("""
                DELETE FROM messages
                WHERE timestamp >= :start_date AND timestamp <= :end_date
                RETURNING id
            """),
            {"start_date": f"{start_date} 00:00:00", "end_date": f"{end_date} 23:59:59"}
        )
        deleted_count = len(delete_result.fetchall())

    await update.message.reply_text(
        f"âœ… åˆ é™¤å®Œæˆï¼\n\n"
        f"ğŸ“„ æ•°æ®åº“è®°å½•ï¼š{deleted_count}/{total_count} æ¡\n"
        f"ğŸ–¼ Cloudinary å›¾ç‰‡ï¼š{deleted_images}/{len(public_ids)} å¼ \n"
        f"ğŸ“… èŒƒå›´ï¼š{start_date} ~ {end_date}"
    )


async def userlogs_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_user.id not in ADMIN_IDS:
        await update.message.reply_text("â›” æ— æƒé™ï¼Œä»…ç®¡ç†å‘˜å¯æŸ¥çœ‹ä»–äººè®°å½•ã€‚")
        return

    if not context.args:
        await update.message.reply_text("âš ï¸ ç”¨æ³•ï¼š/userlogs @ç”¨æˆ·å æˆ– /userlogs ä¸­æ–‡å§“å")
        return

    # 1ï¸âƒ£ è§£ææŸ¥è¯¢å¯¹è±¡
    raw_input = context.args[0]
    is_username = raw_input.startswith("@")
    target_key = raw_input.lstrip("@") if is_username else raw_input

    # 2ï¸âƒ£ è®¡ç®—æœ¬æœˆæ—¶é—´èŒƒå›´
    now = datetime.now(BEIJING_TZ)
    start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
    end = (start + timedelta(days=32)).replace(day=1)

    # 3ï¸âƒ£ è·å–è®°å½•
    if is_username:
        logs = get_user_logs(target_key, start, end)
    else:
        logs = get_user_logs_by_name(target_key, start, end)

    if not logs:
        await update.message.reply_text(f"ğŸ“­ ç”¨æˆ· {target_key} æœ¬æœˆæš‚æ— æ‰“å¡è®°å½•ã€‚")
        return

    # 4ï¸âƒ£ è½¬æ¢æ—¶åŒº & æ’åº
    logs = [(parse(ts) if isinstance(ts, str) else ts, kw, shift) for ts, kw, shift in logs]
    logs = [(ts.astimezone(BEIJING_TZ), kw, shift) for ts, kw, shift in logs]
    logs = sorted(logs, key=lambda x: x[0])

    # 5ï¸âƒ£ æŒ‰å¤©ç»„åˆä¸Šä¸‹ç­æ‰“å¡
    daily_map = defaultdict(dict)
    i = 0
    while i < len(logs):
        ts, kw, shift = logs[i]
        date_key = ts.date()
        if kw == "#ä¸‹ç­æ‰“å¡" and ts.hour < 6:
            date_key = (ts - timedelta(days=1)).date()

        if kw == "#ä¸Šç­æ‰“å¡":
            daily_map[date_key]["shift"] = shift
            daily_map[date_key]["#ä¸Šç­æ‰“å¡"] = ts
            j = i + 1
            while j < len(logs):
                ts2, kw2, _ = logs[j]
                if kw2 == "#ä¸‹ç­æ‰“å¡" and timedelta(0) < (ts2 - ts) <= timedelta(hours=12):
                    daily_map[date_key]["#ä¸‹ç­æ‰“å¡"] = ts2
                    break
                j += 1
            i = j if j > i else i + 1
        else:
            daily_map[date_key]["#ä¸‹ç­æ‰“å¡"] = ts
            i += 1

    # 6ï¸âƒ£ ç»Ÿè®¡
    total_complete = total_abnormal = total_makeup = 0
    for day, kw_map in daily_map.items():
        shift_full = kw_map.get("shift", "æœªé€‰æ‹©ç­æ¬¡")
        is_makeup = shift_full.endswith("ï¼ˆè¡¥å¡ï¼‰")
        shift_name = shift_full.split("ï¼ˆ")[0]
        has_up = "#ä¸Šç­æ‰“å¡" in kw_map
        has_down = "#ä¸‹ç­æ‰“å¡" in kw_map
        has_late = has_early = False

        if is_makeup:
            total_makeup += 1

        if has_up and shift_name in SHIFT_TIMES:
            start_time, _ = SHIFT_TIMES[shift_name]
            if kw_map["#ä¸Šç­æ‰“å¡"].time() > start_time:
                has_late = True

        if has_down and shift_name in SHIFT_TIMES:
            _, end_time = SHIFT_TIMES[shift_name]
            down_ts = kw_map["#ä¸‹ç­æ‰“å¡"]
            if shift_name == "Iç­" and down_ts.date() == day:
                has_early = True
            elif shift_name != "Iç­" and down_ts.time() < end_time:
                has_early = True

        if is_makeup:
            continue
        if has_late:
            total_abnormal += 1
        if has_early:
            total_abnormal += 1
        if not has_late and not has_early and (has_up or has_down):
            total_complete += 2 if has_up and has_down else 1

    # 7ï¸âƒ£ åˆ†é¡µ
    all_days = sorted(daily_map)
    pages = [all_days[i:i + LOGS_PER_PAGE] for i in range(0, len(all_days), LOGS_PER_PAGE)]
    context.user_data["userlogs_pages"] = {
        "pages": pages,
        "daily_map": daily_map,
        "page_index": 0,
        "summary": (total_complete, total_abnormal, total_makeup),
        "target_username": target_key,  # æ— è®ºæ˜¯ username è¿˜æ˜¯ nameï¼Œéƒ½è®°å½•
        "is_username": is_username      # è®°å½•æŸ¥è¯¢æ–¹å¼
    }

    await send_userlogs_page(update, context)  # å±•ç¤ºç¬¬ä¸€é¡µ


# ===========================
# å‘é€åˆ†é¡µå†…å®¹
# ===========================
async def send_userlogs_page(update: Update, context: ContextTypes.DEFAULT_TYPE):
    data = context.user_data["userlogs_pages"]
    pages, daily_map, page_index = data["pages"], data["daily_map"], data["page_index"]
    total_complete, total_abnormal, total_makeup = data["summary"]
    target_username = data["target_username"]

    current_page_days = pages[page_index]
    reply = f"ğŸ—“ï¸ {target_username} æœ¬æœˆæ‰“å¡è®°å½•ï¼ˆç¬¬ {page_index+1}/{len(pages)} é¡µï¼‰ï¼š\n\n"

    for idx, day in enumerate(current_page_days, start=1 + page_index * LOGS_PER_PAGE):
        kw_map = daily_map[day]
        shift_full = kw_map.get("shift", "æœªé€‰æ‹©ç­æ¬¡")
        is_makeup = shift_full.endswith("ï¼ˆè¡¥å¡ï¼‰")
        shift_name = shift_full.split("ï¼ˆ")[0]
        has_up = "#ä¸Šç­æ‰“å¡" in kw_map
        has_down = "#ä¸‹ç­æ‰“å¡" in kw_map
        has_late = has_early = False

        if has_up and shift_name in SHIFT_TIMES:
            start_time, _ = SHIFT_TIMES[shift_name]
            if kw_map["#ä¸Šç­æ‰“å¡"].time() > start_time:
                has_late = True

        if has_down and shift_name in SHIFT_TIMES:
            _, end_time = SHIFT_TIMES[shift_name]
            down_ts = kw_map["#ä¸‹ç­æ‰“å¡"]
            if shift_name == "Iç­" and down_ts.date() == day:
                has_early = True
            elif shift_name != "Iç­" and down_ts.time() < end_time:
                has_early = True

        reply += f"{idx}. {day.strftime('%mæœˆ%dæ—¥')} - {shift_name}\n"
        if has_up:
            reply += f"   â””â”€ #ä¸Šç­æ‰“å¡ï¼š{kw_map['#ä¸Šç­æ‰“å¡'].strftime('%H:%M')}{'ï¼ˆè¡¥å¡ï¼‰' if is_makeup else ''}{'ï¼ˆè¿Ÿåˆ°ï¼‰' if has_late else ''}\n"
        if has_down:
            down_ts = kw_map["#ä¸‹ç­æ‰“å¡"]
            next_day = down_ts.date() > day
            reply += f"   â””â”€ #ä¸‹ç­æ‰“å¡ï¼š{down_ts.strftime('%H:%M')}{'ï¼ˆæ¬¡æ—¥ï¼‰' if next_day else ''}{'ï¼ˆæ—©é€€ï¼‰' if has_early else ''}\n"

    reply += (
        f"\nğŸŸ¢ æ­£å¸¸ï¼š{total_complete} æ¬¡\n"
        f"ğŸ”´ å¼‚å¸¸ï¼ˆè¿Ÿåˆ°/æ—©é€€ï¼‰ï¼š{total_abnormal} æ¬¡\n"
        f"ğŸŸ¡ è¡¥å¡ï¼š{total_makeup} æ¬¡"
    )

    # åˆ†é¡µæŒ‰é’®
    buttons = []
    if page_index > 0:
        buttons.append(InlineKeyboardButton("â¬… ä¸Šä¸€é¡µ", callback_data="userlogs_prev"))
    if page_index < len(pages) - 1:
        buttons.append(InlineKeyboardButton("â¡ ä¸‹ä¸€é¡µ", callback_data="userlogs_next"))
    markup = InlineKeyboardMarkup([buttons]) if buttons else None

    if update.callback_query:
        await update.callback_query.edit_message_text(reply, reply_markup=markup)
    else:
        await update.message.reply_text(reply, reply_markup=markup)

# ===========================
# åˆ†é¡µæŒ‰é’®å›è°ƒ
# ===========================
async def userlogs_page_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()

    if "userlogs_pages" not in context.user_data:
        await query.edit_message_text("âš ï¸ ä¼šè¯å·²è¿‡æœŸï¼Œè¯·é‡æ–°ä½¿ç”¨ /userlogs")
        return

    if query.data == "userlogs_prev":
        context.user_data["userlogs_pages"]["page_index"] -= 1
    elif query.data == "userlogs_next":
        context.user_data["userlogs_pages"]["page_index"] += 1

    await send_userlogs_page(update, context)

# ===========================
# ç”¨æˆ·æ•°æ®è¿ç§»å‘½ä»¤ï¼š/transfer <userA> <userB>
# ===========================
async def transfer_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ç®¡ç†å‘˜å‘½ä»¤ï¼šè¿ç§» userA çš„æ‰€æœ‰æ‰“å¡è®°å½•åˆ° userB"""
    if update.effective_user.id not in ADMIN_IDS:
        await update.message.reply_text("â›” æ— æƒé™ï¼")
        return

    if len(context.args) != 2:
        await update.message.reply_text("ç”¨æ³•ï¼š/transfer <userA> <userB>")
        return

    user_a, user_b = context.args
    try:
        transfer_user_data(user_a, user_b)  # æ‰§è¡Œè¿ç§»
        await update.message.reply_text(f"âœ… å·²å°† {user_a} çš„æ•°æ®è¿ç§»åˆ° {user_b}")
    except ValueError as e:
        await update.message.reply_text(f"âš ï¸ {e}")
    except Exception as e:
        await update.message.reply_text(f"âŒ è¿ç§»å¤±è´¥ï¼š{e}")

# ===========================
# ä¼˜åŒ–æ•°æ®åº“ç´¢å¼•å‘½ä»¤ï¼Œé™åˆ¶ä»…ç®¡ç†å‘˜å¯ç”¨
# ===========================
async def optimize_db(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_user.username not in ADMIN_USERNAMES:
        await update.message.reply_text("âŒ ä½ æ— æƒé™æ‰§è¡Œæ­¤å‘½ä»¤")
        return

    try:
        from db_pg import engine  # å¯¼å…¥å·²æœ‰çš„æ•°æ®åº“å¼•æ“
        sql = """
        CREATE INDEX IF NOT EXISTS messages_id_idx ON messages(id);  -- åˆ›å»ºç´¢å¼•ä»¥ä¼˜åŒ–æŸ¥è¯¢
        CLUSTER messages USING messages_id_idx;  -- æ ¹æ®ç´¢å¼•å¯¹æ•°æ®è¡¨è¿›è¡Œç‰©ç†é‡æ’ï¼ˆèšç°‡ï¼‰
        """
        with engine.begin() as conn:
            conn.execute(text(sql))  # æ‰§è¡Œ SQL

        await update.message.reply_text("âœ… æ•°æ®è¡¨å·²æŒ‰ id è¿›è¡Œä¼˜åŒ–")
    except Exception as e:
        await update.message.reply_text("âš ï¸ æ‰§è¡Œå¤±è´¥ï¼Œè¯·ç¨åå†è¯•")
        print("CLUSTER æ‰§è¡Œå¤±è´¥ï¼š", e)

# ===========================
# ç®¡ç†å‘˜è¡¥å¡å‘½ä»¤
# ===========================
async def admin_makeup_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    ç”¨æ³•ï¼š
    /admin_makeup @username YYYY-MM-DD ç­æ¬¡(F/G/H/I) [ä¸Šç­/ä¸‹ç­]
    - é»˜è®¤è¡¥â€œä¸Šç­â€ï¼Œè‹¥æŒ‡å®šâ€œä¸‹ç­â€åˆ™è¡¥ä¸‹ç­å¡
    """
    # ğŸš© æƒé™æ ¡éªŒ
    if update.effective_user.id not in ADMIN_IDS:
        await update.message.reply_text("âŒ æ— æƒé™ï¼Œä»…ç®¡ç†å‘˜å¯æ“ä½œã€‚")
        return

    # ğŸš© å‚æ•°æ£€æŸ¥
    if len(context.args) not in (3, 4):
        await update.message.reply_text(
            "âš ï¸ ç”¨æ³•ï¼š/admin_makeup @username YYYY-MM-DD ç­æ¬¡(F/G/H/I) [ä¸Šç­/ä¸‹ç­]\n"
            "é»˜è®¤è¡¥ä¸Šç­ï¼Œè‹¥è¦è¡¥ä¸‹ç­éœ€é¢å¤–æŒ‡å®šâ€œä¸‹ç­â€ã€‚"
        )
        return

    # å‚æ•°è§£æ
    username_arg, date_str, shift_code = context.args[:3]
    username = username_arg.lstrip("@")
    shift_code = shift_code.upper()
    punch_type = context.args[3] if len(context.args) == 4 else "ä¸Šç­"

    # ğŸš© æ ¡éªŒç­æ¬¡ä¸æ‰“å¡ç±»å‹
    if shift_code not in SHIFT_OPTIONS:
        await update.message.reply_text("âš ï¸ ç­æ¬¡æ— æ•ˆï¼Œè¯·ä½¿ç”¨ F/G/H/Iã€‚")
        return
    if punch_type not in ("ä¸Šç­", "ä¸‹ç­"):
        await update.message.reply_text("âš ï¸ ç±»å‹å¿…é¡»æ˜¯â€œä¸Šç­â€æˆ–â€œä¸‹ç­â€ã€‚")
        return

    # ğŸš© æ—¥æœŸæ ¼å¼éªŒè¯
    try:
        makeup_date = datetime.strptime(date_str, "%Y-%m-%d").date()
    except ValueError:
        await update.message.reply_text("âš ï¸ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œåº”ä¸º YYYY-MM-DD")
        return

    # è·å–ç”¨æˆ·å§“å
    name = get_user_name(username)
    if not name:
        await update.message.reply_text(f"âš ï¸ ç”¨æˆ· {username} æœªç™»è®°å§“åï¼Œæ— æ³•è¡¥å¡ã€‚")
        return

    # ç­æ¬¡ä¸æ—¶é—´å¤„ç†
    shift_name = SHIFT_OPTIONS[shift_code] + "ï¼ˆè¡¥å¡ï¼‰"
    shift_short = shift_name.split("ï¼ˆ")[0]
    start_time, end_time = SHIFT_TIMES[shift_short]

    if punch_type == "ä¸Šç­":
        # ä¸Šç­è¡¥å¡é€»è¾‘
        punch_dt = datetime.combine(makeup_date, start_time, tzinfo=BEIJING_TZ)
        keyword = "#ä¸Šç­æ‰“å¡"

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ä¸Šç­å¡
        start = datetime.combine(makeup_date, datetime.min.time(), tzinfo=BEIJING_TZ)
        end = start + timedelta(days=1)
        with get_db() as conn:
            cur = conn.cursor()
            cur.execute("""
                SELECT timestamp FROM messages
                WHERE username=%s AND keyword=%s AND timestamp >= %s AND timestamp < %s
            """, (username, keyword, start, end))
            if cur.fetchone():
                await update.message.reply_text(f"âš ï¸ {makeup_date.strftime('%mæœˆ%dæ—¥')} å·²æœ‰ä¸Šç­æ‰“å¡è®°å½•ï¼Œç¦æ­¢é‡å¤è¡¥å¡ã€‚")
                return

    else:  
        # ä¸‹ç­è¡¥å¡é€»è¾‘ï¼ˆè·¨å¤©å¤„ç† I ç­ï¼‰
        if shift_short == "Iç­" and end_time == datetime.strptime("00:00", "%H:%M").time():
            punch_dt = datetime.combine(makeup_date + timedelta(days=1), end_time, tzinfo=BEIJING_TZ)
        else:
            punch_dt = datetime.combine(makeup_date, end_time, tzinfo=BEIJING_TZ)
        keyword = "#ä¸‹ç­æ‰“å¡"

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ä¸‹ç­å¡ï¼ˆIç­éœ€è·¨å¤©æ£€æŸ¥ï¼‰
        if shift_short == "Iç­":
            start = datetime.combine(makeup_date, datetime.min.time(), tzinfo=BEIJING_TZ)
            end = start + timedelta(days=2)
        else:
            start = datetime.combine(makeup_date, datetime.min.time(), tzinfo=BEIJING_TZ)
            end = start + timedelta(days=1)

        with get_db() as conn:
            cur = conn.cursor()
            cur.execute("""
                SELECT timestamp FROM messages
                WHERE username=%s AND keyword=%s AND timestamp >= %s AND timestamp < %s
            """, (username, keyword, start, end))
            if cur.fetchone():
                await update.message.reply_text(f"âš ï¸ {makeup_date.strftime('%mæœˆ%dæ—¥')} å·²æœ‰ä¸‹ç­æ‰“å¡è®°å½•ï¼Œç¦æ­¢é‡å¤è¡¥å¡ã€‚")
                return

    # âœ… å†™å…¥æ•°æ®åº“
    save_message(
        username=username,
        name=name,
        content=f"è¡¥å¡ï¼ˆç®¡ç†å‘˜-{punch_type}ï¼‰",
        timestamp=punch_dt,
        keyword=keyword,
        shift=shift_name
    )

    await update.message.reply_text(
        f"âœ… ç®¡ç†å‘˜å·²ä¸º {name}ï¼ˆ{username}ï¼‰è¡¥å¡ï¼š\n"
        f"ğŸ“… æ—¥æœŸï¼š{makeup_date}\n"
        f"ğŸ· ç­æ¬¡ï¼š{shift_name}\n"
        f"ğŸ”¹ ç±»å‹ï¼š{punch_type}\n"
        f"â° æ—¶é—´ï¼š{punch_dt.strftime('%Y-%m-%d %H:%M')}"
    )
    
# ===========================
# è·å–é»˜è®¤çš„æœˆä»½èŒƒå›´
# ===========================
def get_default_month_range():
    now = datetime.now(BEIJING_TZ)
    start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
    if now.month == 12:
        end = start.replace(year=now.year + 1, month=1)  # è·¨å¹´å¤„ç†
    else:
        end = start.replace(month=now.month + 1)
    return start, end
    
# ===========================
# å¯¼å‡º Excel å‘½ä»¤ï¼š/export [YYYY-MM-DD YYYY-MM-DD]
# ===========================
async def export_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_user.id not in ADMIN_IDS:  # æƒé™æ£€æŸ¥ï¼šä»…ç®¡ç†å‘˜å¯ç”¨
        await update.message.reply_text("âŒ æ— æƒé™ï¼Œä»…ç®¡ç†å‘˜å¯å¯¼å‡ºè®°å½•ã€‚")
        return

    tz = BEIJING_TZ
    args = context.args
    if len(args) == 2:
        # âœ… è§£ææ—¥æœŸå‚æ•°ï¼šå¯¼å‡ºæŒ‡å®šæ—¥æœŸåŒºé—´
        try:
            start = parse(args[0]).replace(tzinfo=tz, hour=0, minute=0, second=0, microsecond=0)
            end = parse(args[1]).replace(tzinfo=tz, hour=23, minute=59, second=59, microsecond=999999)
        except Exception:
            await update.message.reply_text("âš ï¸ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ /export YYYY-MM-DD YYYY-MM-DD")
            return
    else:
        # âœ… æ— å‚æ•°åˆ™é»˜è®¤å¯¼å‡ºæœ¬æœˆ
        start, end = get_default_month_range()

    status_msg = await update.message.reply_text("â³ æ­£åœ¨å¯¼å‡º Excelï¼Œè¯·ç¨ç­‰...")
    file_path = export_excel(start, end)  # è°ƒç”¨å¯¼å‡ºå‡½æ•°ï¼Œè¿”å›æ–‡ä»¶è·¯å¾„æˆ–äº‘ç«¯ URL

    # åˆ é™¤çŠ¶æ€æç¤ºæ¶ˆæ¯
    try:
        await status_msg.delete()
    except:
        pass

    # âœ… å¯¼å‡ºç»“æœå¤„ç†
    if not file_path:
        await update.message.reply_text("âš ï¸ æŒ‡å®šæ—¥æœŸå†…æ²¡æœ‰æ•°æ®ã€‚")
        return

    if file_path.startswith("http"):  
        # æ–‡ä»¶è¿‡å¤§ï¼Œå·²ä¸Šä¼ äº‘ç«¯
        await update.message.reply_text(f"âœ… å¯¼å‡ºå®Œæˆï¼Œæ–‡ä»¶è¿‡å¤§å·²ä¸Šä¼ åˆ°äº‘ç«¯ï¼š\n{file_path}")
    else:
        # ç›´æ¥å‘é€ Excel æ–‡ä»¶å¹¶åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        await update.message.reply_document(document=open(file_path, "rb"))
        os.remove(file_path)

# ===========================
# åœ¨çº¿æ¨¡å¼å¯¼å‡ºå›¾ç‰‡é“¾æ¥ï¼ˆä¸ä¾èµ– _fetch_dataï¼‰
# ===========================
async def export_images_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_user.id not in ADMIN_IDS:
        await update.message.reply_text("âŒ æ— æƒé™ï¼Œä»…ç®¡ç†å‘˜å¯å¯¼å‡ºè®°å½•ã€‚")
        return

    tz = BEIJING_TZ
    args = context.args
    if len(args) == 2:
        try:
            start = parse(args[0]).replace(tzinfo=tz, hour=0, minute=0, second=0, microsecond=0)
            end = parse(args[1]).replace(tzinfo=tz, hour=23, minute=59, second=59, microsecond=999999)
        except Exception:
            await update.message.reply_text("âš ï¸ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ /export_images YYYY-MM-DD YYYY-MM-DD")
            return
    else:
        start, end = get_default_month_range()

    status_msg = await update.message.reply_text("â³ æ­£åœ¨ç”Ÿæˆå›¾ç‰‡é“¾æ¥åˆ—è¡¨ï¼Œè¯·ç¨ç­‰...")

    # ç›´æ¥ä»æ•°æ®åº“æŸ¥è¯¢
    with get_conn() as conn:
        df = pd.read_sql("""
            SELECT timestamp, keyword, name, content
            FROM messages
            WHERE timestamp >= %s AND timestamp <= %s
            ORDER BY timestamp ASC
        """, conn, params=(start, end))

    if df.empty:
        await status_msg.delete()
        await update.message.reply_text("âš ï¸ æŒ‡å®šæ—¥æœŸå†…æ²¡æœ‰æ•°æ®ã€‚")
        return

    # ç­›é€‰å›¾ç‰‡è®°å½•
    photo_df = df[df["content"].str.contains(r"\.(?:jpg|jpeg|png|gif|webp)$", case=False, na=False)].copy()
    if photo_df.empty:
        await status_msg.delete()
        await update.message.reply_text("âš ï¸ æŒ‡å®šæ—¥æœŸå†…æ²¡æœ‰å›¾ç‰‡ã€‚")
        return

    # æå– public_id å¹¶ç”Ÿæˆ Cloudinary URL
    def extract_public_id(url: str) -> str | None:
        match = re.search(r'/upload/(?:v\d+/)?(.+?)\.(?:jpg|jpeg|png|gif|webp)$', url, re.IGNORECASE)
        return match.group(1) if match else None

    photo_df["public_id"] = photo_df["content"].apply(extract_public_id)
    photo_df.dropna(subset=["public_id"], inplace=True)
    if photo_df.empty:
        await status_msg.delete()
        await update.message.reply_text("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„ Cloudinary å›¾ç‰‡é“¾æ¥ã€‚")
        return

    photo_df["url"] = photo_df["public_id"].apply(lambda pid: cloudinary.CloudinaryImage(pid).build_url())

    # ç”Ÿæˆ HTML
    html_lines = [
        "<html><head><meta charset='utf-8'><title>å›¾ç‰‡å¯¼å‡º</title></head><body>",
        f"<h2>å›¾ç‰‡å¯¼å‡ºï¼š{start.strftime('%Y-%m-%d')} è‡³ {end.strftime('%Y-%m-%d')}</h2>"
    ]
    for date_str, group in photo_df.groupby(photo_df["timestamp"].dt.strftime("%Y-%m-%d")):
        html_lines.append(f"<h3>{date_str}</h3><ul>")
        for _, row in group.iterrows():
            ts_local = row["timestamp"].astimezone(BEIJING_TZ).strftime('%H:%M:%S')
            keyword = row.get("keyword", "æ— å…³é”®è¯") or "æ— å…³é”®è¯"
            name = row.get("name", "æœªçŸ¥") or "æœªçŸ¥"
            url = row["url"]
            html_lines.append(
                f"<li>{ts_local} - {keyword} - {name} - <a href='{url}' target='_blank'>æŸ¥çœ‹å›¾ç‰‡</a></li>"
            )
        html_lines.append("</ul>")
    html_lines.append("</body></html>")

    # ä¿å­˜ HTML æ–‡ä»¶
    start_str = start.strftime("%Y-%m-%d")
    end_str = end.strftime("%Y-%m-%d")
    export_dir = os.path.join(DATA_DIR, "links")
    os.makedirs(export_dir, exist_ok=True)
    html_path = os.path.join(export_dir, f"images_links_{start_str}_{end_str}.html")
    with open(html_path, "w", encoding="utf-8") as f:
        f.write("\n".join(html_lines))

    try:
        await status_msg.delete()
    except:
        pass

    # å‘é€ HTML æ–‡ä»¶
    with open(html_path, "rb") as f:
        await update.message.reply_document(document=f, filename=os.path.basename(html_path), caption="âœ… å›¾ç‰‡é“¾æ¥åˆ—è¡¨å·²ç”Ÿæˆ")

    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    os.remove(html_path)
